{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcleods777/LLM-Notebook-Experiments/blob/main/GPT_ChatBot2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "olbOrUTsY21q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76aa3d7b-0d68-4867-9b8a-ea31aacfa344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "#@title Install and Initialize OpenAI\n",
        "!pip install openai\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7_cPohAMAQQ",
        "outputId": "9e8be975-eaec-4369-d8eb-1bacc743c882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount Google Drive\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the directory and filename\n",
        "drive_directory = '/content/drive/MyDrive'\n",
        "log_filename = 'gpt_chatbot.log'\n",
        "\n",
        "# Check for the log file's existence\n",
        "log_path = os.path.join(drive_directory, log_filename)\n",
        "if not os.path.isfile(log_path):\n",
        "    with open(log_path, 'w') as f:\n",
        "        f.write(\"\")\n",
        "\n",
        "# Load message_history from file\n",
        "message_history = []\n",
        "\n",
        "with open(log_path, 'r') as f:\n",
        "    content = f.read()\n",
        "    if content:\n",
        "        message_history = eval(content)\n",
        "\n",
        "def save_message_history():\n",
        "    with open(log_path, 'w') as f:\n",
        "        f.write(str(message_history))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MvH8JFKLcnO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f11fbf5f-6a70-46c8-9434-41214d6a5d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API key: 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\n"
          ]
        }
      ],
      "source": [
        "#@title Input Your API Key Here\n",
        "key_input = input((\"OpenAI API key: \"))\n",
        "openai.api_key = key_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8y8e2BDE3q4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932efd7b-3d15-4d65-91f5-c4e1e9f2ae9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whisper-1\n",
            "babbage\n",
            "davinci\n",
            "text-davinci-edit-001\n",
            "babbage-code-search-code\n",
            "text-similarity-babbage-001\n",
            "code-davinci-edit-001\n",
            "text-davinci-001\n",
            "ada\n",
            "text-davinci-003\n",
            "babbage-code-search-text\n",
            "babbage-similarity\n",
            "code-search-babbage-text-001\n",
            "gpt-3.5-turbo-0301\n",
            "text-curie-001\n",
            "code-search-babbage-code-001\n",
            "text-ada-001\n",
            "text-embedding-ada-002\n",
            "text-similarity-ada-001\n",
            "curie-instruct-beta\n",
            "gpt-3.5-turbo\n",
            "ada-code-search-code\n",
            "ada-similarity\n",
            "code-search-ada-text-001\n",
            "text-search-ada-query-001\n",
            "davinci-search-document\n",
            "ada-code-search-text\n",
            "text-search-ada-doc-001\n",
            "davinci-instruct-beta\n",
            "text-similarity-curie-001\n",
            "code-search-ada-code-001\n",
            "ada-search-query\n",
            "text-search-davinci-query-001\n",
            "curie-search-query\n",
            "davinci-search-query\n",
            "babbage-search-document\n",
            "ada-search-document\n",
            "gpt-4-0314\n",
            "text-search-curie-query-001\n",
            "text-search-babbage-doc-001\n",
            "gpt-4\n",
            "curie-search-document\n",
            "text-search-curie-doc-001\n",
            "babbage-search-query\n",
            "text-babbage-001\n",
            "text-search-davinci-doc-001\n",
            "text-search-babbage-query-001\n",
            "curie-similarity\n",
            "curie\n",
            "text-similarity-davinci-001\n",
            "text-davinci-002\n",
            "davinci-similarity\n",
            "cushman:2020-05-03\n",
            "ada:2020-05-03\n",
            "babbage:2020-05-03\n",
            "curie:2020-05-03\n",
            "davinci:2020-05-03\n",
            "if-davinci-v2\n",
            "if-curie-v2\n",
            "if-davinci:3.0.0\n",
            "davinci-if:3.0.0\n",
            "davinci-instruct-beta:2.0.0\n",
            "text-ada:001\n",
            "text-davinci:001\n",
            "text-curie:001\n",
            "text-babbage:001\n",
            "davinci:ft-personal-2022-12-07-17-31-40\n"
          ]
        }
      ],
      "source": [
        "#@title Get a list of available models\n",
        "\n",
        "\n",
        "models = openai.Model.list()\n",
        "\n",
        "# Print the list of models\n",
        "for model in models['data']:\n",
        "    print(model['id'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3A30dlYgCP5W"
      },
      "outputs": [],
      "source": [
        "#@title Choose model (GPTChat is gpt-3.5-turbo, GPT-4 is gpt-4)\n",
        "\n",
        "model = \"gpt-3.5-turbo\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WaCIE08QAIR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E1DBBEfY6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "ba4d1381-c32c-433f-a43f-706df8f194a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> hi there\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hello! How may I assist you today?\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Tokens used:** 19"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<hr>"
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> How was rome built\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The city of Rome was built over a period of many centuries, with its construction beginning in the 8th century BC. According to legend, the city was founded by the twin brothers Romulus and Remus, who were saved and raised by a she-wolf. \n\nRome's strategic location along the Tiber River provided it with access to trade routes and fertile farmland, and its hills offered defensible positions. The city's early development was heavily influenced by the Etruscans, who lived in central Italy before the rise of Rome. \n\nThe first Roman structures were small huts built out of mud and wood on top of the Palatine Hill. During the 7th and 6th centuries BC, these huts were replaced with larger, more permanent structures made of stone and brick. The Romans also built an extensive network of roads to connect their growing city with other parts of Italy.\n\nOver time, Rome grew into the largest city in the world, boasting impressive public buildings, aqueducts, temples, and other monumental structures. The city's architecture reflected the influence of various cultures, including the Greeks and Egyptians.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Tokens used:** 264"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<hr>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Initiate Conversation With ChatBot\n",
        "import openai\n",
        "from IPython.display import display, Markdown, HTML\n",
        "\n",
        "def chat(inp, role=\"user\"):\n",
        "    message_history.append({\"role\": role, \"content\": f\"{inp}\"})\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=message_history\n",
        "    )\n",
        "\n",
        "    reply_content = completion.choices[0].message.content\n",
        "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})\n",
        "\n",
        "    tokens_used = completion.usage['total_tokens']\n",
        "    return reply_content, tokens_used\n",
        "\n",
        "# Initializing an empty message_history list\n",
        "message_history = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"> \")\n",
        "    if user_input == \"EXITNOW\":\n",
        "        break\n",
        "    display(Markdown(\"\\n\"))\n",
        "    reply, tokens = chat(user_input)\n",
        "    display(Markdown(reply + \"\\n\"))\n",
        "    display(Markdown(f\"**Tokens used:** {tokens}\"))\n",
        "    display(Markdown(\"\\n\"))\n",
        "    display(HTML(\"<hr>\"))\n",
        "\n",
        "display(Markdown(\"\\n\"))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}